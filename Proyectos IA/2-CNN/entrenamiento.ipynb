{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f1aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurando mejoras de robustez...\n",
      "Iniciando entrenamiento robusto...\n",
      "Epoch 1/100\n",
      "\u001b[1m 63/529\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 109ms/step - accuracy: 0.4358 - loss: 1.5006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIniciando entrenamiento robusto...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# Nota: Usamos datagen.flow para el entrenamiento, pero los datos normales para validación\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatagen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Ponemos muchas, el EarlyStopping lo detendrá cuando sea necesario\u001b[39;49;00m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks_list\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Guardar mapa de clases\u001b[39;00m\n\u001b[32m     95\u001b[39m np.save(\u001b[33m'\u001b[39m\u001b[33mclases.npy\u001b[39m\u001b[33m'\u001b[39m, clases_validas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:400\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    398\u001b[39m callbacks.on_train_batch_begin(begin_step)\n\u001b[32m    399\u001b[39m logs = \u001b[38;5;28mself\u001b[39m.train_function(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m \u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py:198\u001b[39m, in \u001b[36mCallbackList.on_train_batch_end\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28mself\u001b[39m._async_dispatch(\u001b[38;5;28mself\u001b[39m._on_train_batch_end, batch, logs)\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_on_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py:220\u001b[39m, in \u001b[36mCallbackList._on_train_batch_end\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    218\u001b[39m logs = python_utils.pythonify_logs(logs)\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     \u001b[43mcallback\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\site-packages\\keras\\src\\callbacks\\progbar_logger.py:58\u001b[39m, in \u001b[36mProgbarLogger.on_train_batch_end\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\site-packages\\keras\\src\\callbacks\\progbar_logger.py:95\u001b[39m, in \u001b[36mProgbarLogger._update_progbar\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.seen = batch + \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprogbar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\site-packages\\keras\\src\\utils\\progbar.py:179\u001b[39m, in \u001b[36mProgbar.update\u001b[39m\u001b[34m(self, current, values, finalize)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m finalize:\n\u001b[32m    177\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43mio_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28mself\u001b[39m._prev_total_width = total_width\n\u001b[32m    181\u001b[39m message = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\site-packages\\keras\\src\\utils\\io_utils.py:111\u001b[39m, in \u001b[36mprint_msg\u001b[39m\u001b[34m(message, line_break)\u001b[39m\n\u001b[32m    109\u001b[39m         message = message_bytes.decode(encoding)\n\u001b[32m    110\u001b[39m         sys.stdout.write(message)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    113\u001b[39m     logging.info(message)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\iostream.py:604\u001b[39m, in \u001b[36mOutStream.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28mself\u001b[39m.pub_thread.schedule(evt.set)\n\u001b[32m    603\u001b[39m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    605\u001b[39m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[32m    606\u001b[39m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[32m    607\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mIOStream.flush timed out\u001b[39m\u001b[33m\"\u001b[39m, file=sys.__stderr__)\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    627\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gabri\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\threading.py:331\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    333\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU, Input, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "\n",
    "# --- 1. CONFIGURACIÓN ---\n",
    "DIRECTORIO_DATASET = os.path.abspath(\"./dataset\") \n",
    "ANCHO = 64  \n",
    "ALTO = 64\n",
    "CANALES = 3 \n",
    "\n",
    "print(f\"Buscando en: {DIRECTORIO_DATASET}\")\n",
    "\n",
    "if not os.path.exists(DIRECTORIO_DATASET):\n",
    "    print(f\"❌ ERROR: No encuentro la carpeta '{DIRECTORIO_DATASET}'. Asegúrate de estar en el directorio correcto.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. CARGA DE DATOS ---\n",
    "# Detectar clases\n",
    "clases_validas = [d for d in os.listdir(DIRECTORIO_DATASET) if os.path.isdir(os.path.join(DIRECTORIO_DATASET, d))]\n",
    "clases_validas.sort()\n",
    "mapa_clases = {nombre: i for i, nombre in enumerate(clases_validas)}\n",
    "\n",
    "print(f\"Clases detectadas ({len(clases_validas)}): {clases_validas}\")\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "print(\"Cargando imágenes...\")\n",
    "for nombre_clase in clases_validas:\n",
    "    ruta_clase = os.path.join(DIRECTORIO_DATASET, nombre_clase)\n",
    "    archivos = os.listdir(ruta_clase)\n",
    "    \n",
    "    count = 0\n",
    "    for archivo in archivos:\n",
    "        if archivo.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')):\n",
    "            ruta_imagen = os.path.join(ruta_clase, archivo)\n",
    "            try:\n",
    "                img = imread(ruta_imagen)\n",
    "                \n",
    "                # Quitar transparencia (Alpha) si existe\n",
    "                if len(img.shape) == 3 and img.shape[2] == 4:\n",
    "                     img = img[:, :, :3]\n",
    "                \n",
    "                # Redimensionar\n",
    "                img_resized = resize(img, (ALTO, ANCHO), anti_aliasing=True, preserve_range=True)\n",
    "                \n",
    "                # Asegurar 3 canales RGB\n",
    "                if len(img_resized.shape) == 3 and img_resized.shape[2] == 3:\n",
    "                    images.append(img_resized)\n",
    "                    labels.append(mapa_clases[nombre_clase]) \n",
    "                    count += 1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    print(f\"    {nombre_clase}: {count} imágenes\")\n",
    "\n",
    "# --- 3. PREPROCESAMIENTO ---\n",
    "if len(images) == 0:\n",
    "    print(\"❌ Error: No se cargaron imágenes. Revisa tu dataset.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Procesando datos...\")\n",
    "X = np.array(images, dtype=np.float32) / 255.0 \n",
    "y = np.array(labels)\n",
    "y_one_hot = to_categorical(y, num_classes=len(clases_validas))\n",
    "\n",
    "print(f\"Datos listos: X={X.shape}, y={y_one_hot.shape}\")\n",
    "\n",
    "# Separar Train/Test\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- 4. DATA AUGMENTATION (MEJORA DE ROBUSTEZ) ---\n",
    "# Crea variaciones de las imágenes en tiempo real para evitar overfitting\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# --- 5. MODELO MEJORADO ---\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(ALTO, ANCHO, CANALES)))\n",
    "\n",
    "# Bloque 1\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization()) # Normaliza para aprender más rápido\n",
    "model.add(LeakyReLU(negative_slope=0.1))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25)) # Apaga neuronas al azar para evitar memorización\n",
    "\n",
    "# Bloque 2\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(negative_slope=0.1))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Bloque 3 (Más profundo para características complejas)\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(negative_slope=0.1))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Clasificador (Dense)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU(negative_slope=0.1))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(len(clases_validas), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# --- 6. CALLBACKS (SALVAVIDAS) ---\n",
    "callbacks_list = [\n",
    "    # Parar si no mejora la validación en 10 épocas\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "    # Guardar solo el mejor modelo\n",
    "    ModelCheckpoint('mejor_modelo.h5', monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    # Bajar la velocidad de aprendizaje si se estanca\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "# --- 7. ENTRENAMIENTO ---\n",
    "print(\"Iniciando entrenamiento robusto...\")\n",
    "# Usamos datagen.flow para el set de entrenamiento\n",
    "history = model.fit(\n",
    "    datagen.flow(train_X, train_Y, batch_size=32),\n",
    "    epochs=100, # Ponemos un tope alto, EarlyStopping lo detendrá antes si es necesario\n",
    "    validation_data=(test_X, test_Y),\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "# --- 8. GUARDAR Y GRAFICAR ---\n",
    "model.save(\"modelo_final_robusto.h5\")\n",
    "np.save('clases.npy', clases_validas)\n",
    "print(\"Archivos guardados: 'modelo_final_robusto.h5' y 'clases.npy'\")\n",
    "\n",
    "# Gráficas de rendimiento\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gráfica de Precisión (Accuracy)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "plt.title('Precisión del Modelo')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Gráfica de Pérdida (Loss)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida (Loss)')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
